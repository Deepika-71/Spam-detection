{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNlMi8CH/FPj0j28hTVI2zd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":761},"id":"Nx8YRKR2Fwg9","executionInfo":{"status":"ok","timestamp":1753288291540,"user_tz":-330,"elapsed":9341,"user":{"displayName":"T Deepika","userId":"18442775670131084992"}},"outputId":"da99c40c-fa45-47f0-8f67-58bccfa2eebd"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling1d_1      │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling1d_1      │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n","Epoch 1/10\n","117/117 - 3s - 25ms/step - accuracy: 0.7886 - loss: 0.5748 - val_accuracy: 0.8357 - val_loss: 0.4317\n","Epoch 2/10\n","117/117 - 0s - 4ms/step - accuracy: 0.8681 - loss: 0.3537 - val_accuracy: 0.9010 - val_loss: 0.2376\n","Epoch 3/10\n","117/117 - 0s - 4ms/step - accuracy: 0.9363 - loss: 0.2113 - val_accuracy: 0.9710 - val_loss: 0.1454\n","Epoch 4/10\n","117/117 - 1s - 5ms/step - accuracy: 0.9651 - loss: 0.1401 - val_accuracy: 0.9758 - val_loss: 0.1026\n","Epoch 5/10\n","117/117 - 0s - 4ms/step - accuracy: 0.9758 - loss: 0.1012 - val_accuracy: 0.9855 - val_loss: 0.0801\n","Epoch 6/10\n","117/117 - 1s - 5ms/step - accuracy: 0.9828 - loss: 0.0772 - val_accuracy: 0.9783 - val_loss: 0.0717\n","Epoch 7/10\n","117/117 - 0s - 4ms/step - accuracy: 0.9871 - loss: 0.0643 - val_accuracy: 0.9928 - val_loss: 0.0579\n","Epoch 8/10\n","117/117 - 1s - 5ms/step - accuracy: 0.9874 - loss: 0.0530 - val_accuracy: 0.9831 - val_loss: 0.0507\n","Epoch 9/10\n","117/117 - 1s - 6ms/step - accuracy: 0.9879 - loss: 0.0472 - val_accuracy: 0.9807 - val_loss: 0.0559\n","Epoch 10/10\n","117/117 - 0s - 4ms/step - accuracy: 0.9898 - loss: 0.0410 - val_accuracy: 0.9831 - val_loss: 0.0433\n","\n","✅ Test Accuracy: 97.97%\n"]}],"source":["import pandas as pd\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import layers, models\n","from sklearn.model_selection import train_test_split\n","\n","# 0. Download stopwords if not already done\n","nltk.download('stopwords')\n","\n","# 1. Load the data\n","data = pd.read_csv('Emails.csv')  # ensure this file exists in working dir\n","data = data[['label', 'text']].dropna()  # drop missing values, changed 'message' to 'text'\n","data['label'] = data['label'].map({'ham': 0, 'spam': 1})  # map labels\n","\n","# 2. Text cleaning function\n","stop_words = set(stopwords.words('english'))\n","def clean_text(text: str) -> str:\n","    text = text.lower()\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    tokens = text.split()\n","    tokens = [w for w in tokens if w not in stop_words]\n","    return ' '.join(tokens)\n","\n","data['cleaned'] = data['text'].apply(clean_text) # changed 'message' to 'text'\n","\n","# 3. Tokenize and pad sequences\n","MAX_VOCAB = 5000\n","MAX_LEN = 100\n","\n","tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(data['cleaned'])\n","\n","sequences = tokenizer.texts_to_sequences(data['cleaned'])\n","X = pad_sequences(sequences, maxlen=MAX_LEN, truncating='post')\n","y = data['label'].values\n","\n","# 4. Train/test split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# 5. Build the Sequential model\n","model = models.Sequential([\n","    layers.Embedding(input_dim=MAX_VOCAB, output_dim=16, input_length=MAX_LEN),\n","    layers.GlobalAveragePooling1D(),\n","    layers.Dense(16, activation='relu'),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","print(model.summary())\n","\n","# 6. Train the model with validation split\n","history = model.fit(\n","    X_train, y_train,\n","    epochs=10,\n","    batch_size=32,\n","    validation_split=0.1,\n","    verbose=2\n",")\n","\n","# 7. Evaluate on test set\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"\\n✅ Test Accuracy: {accuracy * 100:.2f}%\")\n","\n","# 8. Prediction helper function\n","def predict_email(text: str) -> str:\n","    text_clean = clean_text(text)\n","    seq = tokenizer.texts_to_sequences([text_clean])\n","    pad = pad_sequences(seq, maxlen=MAX_LEN, truncating='post')\n","    pred = model.predict(pad, verbose=0)[0][0]\n","    return \"SPAM\" if pred > 0.5 else \"HAM\""]}]}